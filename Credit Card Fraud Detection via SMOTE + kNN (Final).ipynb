{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2x2Z58K5fF-"
   },
   "source": [
    "# Predicting if credit card usage is fraud or not using KNN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocqzIAST5tRL"
   },
   "source": [
    "In this notebook, we explore the credit card fraud dataset from: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "\n",
    "The purpose of this notebook is to use the k-nearest neighbour classfier algorithm to identify fraudulent use of credit cards based on 28 different variables with 280,000 points of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moAFnVL9fRT-"
   },
   "source": [
    "# Why kNN?\n",
    "\n",
    "We use kNN because the data we are about to use is highly multi-dimensional (x = 28), and this can imply that there are complex, non-linear relationships between each variables that could be difficult to model.\n",
    "\n",
    "Furthermore, kNN classifiers make no assumptions about the underlying distributions of the data (as opposed to some methods that assume the data is normally distributed), which makes it a useful technique when dealing with highly skewed data like this one.\n",
    "\n",
    "Let's first import all the libraries we need. We will be using methods inside the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "d-s2uQmr5gHU"
   },
   "outputs": [],
   "source": [
    "import numpy as np #linear algebra\n",
    "import pandas as pd #dataframe manipulation\n",
    "import csv #excel file\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split #split train data\n",
    "from sklearn.preprocessing import StandardScaler #Standardize features by removing the mean and scaling to unit variance.\n",
    "from sklearn.neighbors import KNeighborsClassifier # Classifier implementing the k-nearest neighbors vote.\n",
    "from sklearn.metrics import confusion_matrix #testing for false positive and negative\n",
    "from sklearn.metrics import f1_score #Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "from sklearn.metrics import accuracy_score #The accuracy_score function computes the accuracy, either the fraction (default) or the count (normalize=False) of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3isQeuz6jBo"
   },
   "source": [
    "Here we'll be importing the csv file from the Kaggle notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "CxRkEBWn6rTU",
    "outputId": "ca34ea39-99ff-4926-b67b-c534b0226981",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must first perform some Exploratory Data Analysis to get a sense of our data. Let's take a look at what our dataframe looks like first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understandably, it looks like to all the names of the variables have been removed for security purposes of the credit card company that provided this dataset. \n",
    "\n",
    "It is then up to us to figure out which variables, unknown as they are, are the most predictive in telling which creditcard usages are frauds. \n",
    "\n",
    "A good place to start is to see if there are any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good news! We lucked out, and this dataset seems to be well prepared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many of the rows of data were actually fraudulent out of all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284807\n",
      "492\n",
      "0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "count = 0;\n",
    "for x in df.iloc[:,-1]:\n",
    "    if (x == 1):\n",
    "        count=count+1\n",
    "print(len(df))\n",
    "print(count)\n",
    "ratio = count/len(df)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the actual number of fraud usage is only 0.172% of the entire dataset. We can view this bimodal distribution as a pie chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Class'>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df['Class']\n",
    "y.value_counts().plot.pie(autopct='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ece9HHZx91kt"
   },
   "source": [
    "### Now, to train our model, we must prepare the training and the testing sets to fit the model. We randomly select 80% and 20% of the data for training and testing sets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "3utBCTcu-C8M"
   },
   "outputs": [],
   "source": [
    "#Define x train, x test, y train, y test\n",
    "X = df.iloc[:,0:30]\n",
    "y = df.iloc[:,30]\n",
    "# random_state = 0:\n",
    "##  Passes an int for reproducible output across multiple function calls.\n",
    "# test_size = 0.2:\n",
    "##   should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npBESEWT-Kdu"
   },
   "source": [
    "Now, notice that in our data, the numerical values in V1 to V27 are very low compared to the values in \"Amount\" column. This can cause problems in the training of the model because the model can interpret the low values of columns 1 to 28 as an insignificant variable.\n",
    "\n",
    "To prevent this, we normalize our data. This means that we standardize the values so the units become \"x number of standard deviations from the mean\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "g5T9qTtHDMZx"
   },
   "outputs": [],
   "source": [
    "#normalize data\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpR70uQODUJY"
   },
   "source": [
    "Now we define our k nearest neighbour algorithm. There is no standard set number of neighbours; so we use k = 11.\n",
    "\n",
    "The way that the knn classifier works, is that for every point on the data, it calculates the Euclidean distance between each point and its 11 neighbouring points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtaCbLs_Efmm",
    "outputId": "fd398124-8a74-4751-92f9-fcb33de853b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11 neighbours for each point, p = 2 sets calculation of each point to the neighbours to use euclidean distance.\n",
    "classifier = KNeighborsClassifier(n_neighbors = 11, p =2, metric = 'euclidean')\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQTmxgnRGbsS"
   },
   "source": [
    "Now, since our prediction data is binary (is fraud, is not fraud), we could try to create a confusion matrix to test for false positive/negatives and true positive/negatives.\n",
    "\n",
    "However, because our data is so heavily imbalanaced (284,807 transactions, 492 frauds), it is difficult for the KNN classifier to set a proper threshold for classifying a data point as fraud; therefore a confusion matrix is not useful.\n",
    "\n",
    "Instead, we use the Precision-Recall Area Under the Curve (PRAUC).\n",
    "\n",
    "Precision is simply the proportion of positive results that were correctly classified. **It is useful because Precision doesant use the number of True Negatievs in its calculation; thus not affected by the distribution imbalance.**\n",
    "\n",
    "$Precision = \\frac{True Positives}{True Positives + False Positives}$\n",
    "\n",
    "And Recall is the proportion of correct positive classifications out of all positive predictions (whether they were correct or not).\n",
    "\n",
    "$Recall = \\frac{True Positives}{True Positives + False Negatives}$\n",
    "\n",
    "So, let's plot the PRAUC. First we need to import a couple more libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "SJeMcVc-IH0X"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qkDxQO2JOBw"
   },
   "source": [
    "Here, we define y_scores with the predict_proba function on X_test testing set dataframe to assign a likelihood percentage of belong in either class (not fraud = 0, fraud = 1). Let's see what the first element of y_score looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "snZ8_mo5ItFp"
   },
   "outputs": [],
   "source": [
    "y_scores = classifier.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNndWvSyIz1j",
    "outputId": "07700796-7952-44cb-f295-8deb1b23494c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 [0.90909091 0.09090909]\n",
      "159 [0.18181818 0.81818182]\n",
      "365 [0.09090909 0.90909091]\n",
      "1088 [0.90909091 0.09090909]\n",
      "1241 [0.90909091 0.09090909]\n",
      "1795 [0.90909091 0.09090909]\n",
      "1976 [0.90909091 0.09090909]\n",
      "3371 [0.90909091 0.09090909]\n",
      "3682 [0.90909091 0.09090909]\n",
      "4608 [0.81818182 0.18181818]\n",
      "5286 [0.63636364 0.36363636]\n",
      "6122 [0.36363636 0.63636364]\n",
      "6893 [0.18181818 0.81818182]\n",
      "6940 [0.18181818 0.81818182]\n",
      "7418 [0.90909091 0.09090909]\n",
      "7496 [0.45454545 0.54545455]\n",
      "7924 [0.90909091 0.09090909]\n",
      "8072 [0.18181818 0.81818182]\n",
      "8139 [0.36363636 0.63636364]\n",
      "8227 [0.09090909 0.90909091]\n",
      "8297 [0.90909091 0.09090909]\n",
      "8374 [0.09090909 0.90909091]\n",
      "8754 [0.90909091 0.09090909]\n",
      "8834 [0.90909091 0.09090909]\n",
      "8914 [0.90909091 0.09090909]\n",
      "9062 [0.54545455 0.45454545]\n",
      "9126 [0.90909091 0.09090909]\n",
      "9140 [0.18181818 0.81818182]\n",
      "9270 [0.90909091 0.09090909]\n",
      "9335 [0.90909091 0.09090909]\n",
      "9365 [0.90909091 0.09090909]\n",
      "9459 [0.90909091 0.09090909]\n",
      "9744 [0.09090909 0.90909091]\n",
      "9757 [0.18181818 0.81818182]\n",
      "9825 [0.90909091 0.09090909]\n",
      "9895 [0.81818182 0.18181818]\n",
      "9941 [0.18181818 0.81818182]\n",
      "9999 [0.90909091 0.09090909]\n",
      "10291 [0.09090909 0.90909091]\n",
      "10860 [0.36363636 0.63636364]\n",
      "11003 [0.90909091 0.09090909]\n",
      "11442 [0.90909091 0.09090909]\n",
      "11522 [0.54545455 0.45454545]\n",
      "11974 [0.90909091 0.09090909]\n",
      "12618 [0.54545455 0.45454545]\n",
      "13034 [0.81818182 0.18181818]\n",
      "13402 [0.90909091 0.09090909]\n",
      "13797 [0.27272727 0.72727273]\n",
      "14842 [0.90909091 0.09090909]\n",
      "14861 [0.90909091 0.09090909]\n",
      "14955 [0.63636364 0.36363636]\n",
      "15373 [0.63636364 0.36363636]\n",
      "15378 [0.90909091 0.09090909]\n",
      "16155 [0.90909091 0.09090909]\n",
      "16224 [0.90909091 0.09090909]\n",
      "16410 [0.81818182 0.18181818]\n",
      "16460 [0.72727273 0.27272727]\n",
      "17344 [0.90909091 0.09090909]\n",
      "17834 [0.90909091 0.09090909]\n",
      "18041 [0.90909091 0.09090909]\n",
      "18490 [0.90909091 0.09090909]\n",
      "19991 [0.54545455 0.45454545]\n",
      "20240 [0.90909091 0.09090909]\n",
      "20438 [0.90909091 0.09090909]\n",
      "20536 [0.90909091 0.09090909]\n",
      "20838 [0.90909091 0.09090909]\n",
      "21067 [0.90909091 0.09090909]\n",
      "21461 [0.90909091 0.09090909]\n",
      "21676 [0.90909091 0.09090909]\n",
      "22124 [0.63636364 0.36363636]\n",
      "22226 [0.90909091 0.09090909]\n",
      "22496 [0.72727273 0.27272727]\n",
      "22980 [0.90909091 0.09090909]\n",
      "23102 [0.09090909 0.90909091]\n",
      "23112 [0.18181818 0.81818182]\n",
      "23208 [0.90909091 0.09090909]\n",
      "23346 [0.90909091 0.09090909]\n",
      "24520 [0.09090909 0.90909091]\n",
      "24725 [0.90909091 0.09090909]\n",
      "25296 [0.90909091 0.09090909]\n",
      "25369 [0.90909091 0.09090909]\n",
      "25629 [0.72727273 0.27272727]\n",
      "26516 [0.90909091 0.09090909]\n",
      "26968 [0.90909091 0.09090909]\n",
      "27509 [0.18181818 0.81818182]\n",
      "27595 [0.18181818 0.81818182]\n",
      "28031 [0.90909091 0.09090909]\n",
      "28239 [0.90909091 0.09090909]\n",
      "29946 [0.90909091 0.09090909]\n",
      "30244 [0.09090909 0.90909091]\n",
      "30250 [0.90909091 0.09090909]\n",
      "30986 [0.27272727 0.72727273]\n",
      "31059 [0.63636364 0.36363636]\n",
      "31551 [0.90909091 0.09090909]\n",
      "31836 [0.90909091 0.09090909]\n",
      "32179 [0.09090909 0.90909091]\n",
      "32385 [0.90909091 0.09090909]\n",
      "33034 [0.90909091 0.09090909]\n",
      "33083 [0.90909091 0.09090909]\n",
      "33243 [0.90909091 0.09090909]\n",
      "34378 [0.90909091 0.09090909]\n",
      "35320 [0.54545455 0.45454545]\n",
      "35435 [0.72727273 0.27272727]\n",
      "36316 [0.81818182 0.18181818]\n",
      "37127 [0.45454545 0.54545455]\n",
      "37501 [0.09090909 0.90909091]\n",
      "37652 [0.63636364 0.36363636]\n",
      "39039 [0.90909091 0.09090909]\n",
      "39539 [0.90909091 0.09090909]\n",
      "39697 [0.90909091 0.09090909]\n",
      "39947 [0.90909091 0.09090909]\n",
      "40034 [0.90909091 0.09090909]\n",
      "40399 [0.90909091 0.09090909]\n",
      "40410 [0.90909091 0.09090909]\n",
      "41067 [0.54545455 0.45454545]\n",
      "41201 [0.09090909 0.90909091]\n",
      "41321 [0.81818182 0.18181818]\n",
      "41434 [0.63636364 0.36363636]\n",
      "41488 [0.90909091 0.09090909]\n",
      "41546 [0.45454545 0.54545455]\n",
      "41714 [0.90909091 0.09090909]\n",
      "41751 [0.90909091 0.09090909]\n",
      "42029 [0.90909091 0.09090909]\n",
      "42156 [0.45454545 0.54545455]\n",
      "42431 [0.90909091 0.09090909]\n",
      "42510 [0.63636364 0.36363636]\n",
      "42564 [0.18181818 0.81818182]\n",
      "42672 [0.18181818 0.81818182]\n",
      "43191 [0.90909091 0.09090909]\n",
      "43583 [0.90909091 0.09090909]\n",
      "43681 [0.27272727 0.72727273]\n",
      "43682 [0.90909091 0.09090909]\n",
      "44402 [0.90909091 0.09090909]\n",
      "44441 [0.90909091 0.09090909]\n",
      "44464 [0.45454545 0.54545455]\n",
      "44555 [0.90909091 0.09090909]\n",
      "44834 [0.90909091 0.09090909]\n",
      "45249 [0.09090909 0.90909091]\n",
      "45430 [0.90909091 0.09090909]\n",
      "45485 [0.63636364 0.36363636]\n",
      "45792 [0.45454545 0.54545455]\n",
      "46317 [0.90909091 0.09090909]\n",
      "46434 [0.09090909 0.90909091]\n",
      "46472 [0.90909091 0.09090909]\n",
      "46903 [0.09090909 0.90909091]\n",
      "47294 [0.90909091 0.09090909]\n",
      "47371 [0.90909091 0.09090909]\n",
      "47437 [0.90909091 0.09090909]\n",
      "47918 [0.90909091 0.09090909]\n",
      "48466 [0.90909091 0.09090909]\n",
      "48742 [0.81818182 0.18181818]\n",
      "48763 [0.90909091 0.09090909]\n",
      "48969 [0.90909091 0.09090909]\n",
      "49033 [0.90909091 0.09090909]\n",
      "49377 [0.90909091 0.09090909]\n",
      "49609 [0.90909091 0.09090909]\n",
      "49630 [0.63636364 0.36363636]\n",
      "49663 [0.09090909 0.90909091]\n",
      "49692 [0.90909091 0.09090909]\n",
      "49735 [0.90909091 0.09090909]\n",
      "49889 [0.90909091 0.09090909]\n",
      "50043 [0.90909091 0.09090909]\n",
      "50983 [0.90909091 0.09090909]\n",
      "51817 [0.54545455 0.45454545]\n",
      "51940 [0.90909091 0.09090909]\n",
      "52172 [0.09090909 0.90909091]\n",
      "52244 [0.63636364 0.36363636]\n",
      "52396 [0.90909091 0.09090909]\n",
      "52623 [0.27272727 0.72727273]\n",
      "52687 [0.09090909 0.90909091]\n",
      "52927 [0.90909091 0.09090909]\n",
      "52983 [0.81818182 0.18181818]\n",
      "53012 [0.63636364 0.36363636]\n",
      "53584 [0.90909091 0.09090909]\n",
      "54204 [0.90909091 0.09090909]\n",
      "55249 [0.90909091 0.09090909]\n",
      "56539 [0.18181818 0.81818182]\n",
      "56552 [0.90909091 0.09090909]\n"
     ]
    }
   ],
   "source": [
    "for index, x in enumerate(y_scores):\n",
    "  if (x[1] != 0) and (x[1] != 1):\n",
    "    print(index,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgK0r_7RLWL_"
   },
   "source": [
    "Above we print out all the data points that aren't [0,1] or [1,0]; meaning we only want to see the points that the KNN classifier wasn't 100% sure whether if it was a fraud or not. As we can see that both values in each output adds upto 1, and each values are percentages of each point belonging to either classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sohzfq0MO9rA"
   },
   "source": [
    "Now we move on to determining false/true positive rates of the y_test testing set. The y_scores[:,1] are the values of the likelihood of the sample being a fraud that was obtained from the predict_proba method, imposed on the y_test set.\n",
    "\n",
    "This returns the false positive rate, true positive rate, and the decreasing threshold that is used to calculate fpr and tpr.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "bmvqrFEgLSpr"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QefSpHmYTNfF"
   },
   "source": [
    "Finally, let's see what this graph looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "hXGVgismTP2U",
    "outputId": "82e1b85b-5e1d-4fdd-c5fc-f2473314be73"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'b--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN classifier ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF2cTK3eUKx8"
   },
   "source": [
    "We see above that the threshold can sit around 0 FPR and still achieve a TRP of approximately 0.85. Depending on how much FPR we are comfortable with, we may accept thresholds slightly past the (0.0,0.85) point. However, the AUC of 0.93 is a fairly acceptable result. The drastic upchange in the curve is most likely due to the fact that there are very little positive cases of fraud compared to the negative cases, such that when the threshold for True Positive classification is met, the true negative cases.\n",
    "\n",
    "0.93 is not a terrible result, but let's see if we can do any better. Here we implement the SMOTE technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing SMOTE technique\n",
    "\n",
    "We employ the SMOTE technique here to improve our kNN classifier. SMOTE works by generating a synthetic positive class point in our data. \n",
    "\n",
    "The way it works is relatively simple: \n",
    "\n",
    "1. Choose a positive class example in our data. \n",
    "2. Choose a number of neighbours to observe around this data. For example, take 3 neighbours. \n",
    "3. For each of its neighbours, choose a random number between 0 and 1, and multiply this number by the distance from the chosen data to its 1st neighbour \n",
    "4. Generate a new synthetic positive data at this location. \n",
    "5. Continue for all positive class data. \n",
    "\n",
    "$\\textbf{We must understand, however, the tradeoff of accuracy and overfitting must be taken into consideration.}$\n",
    "\n",
    "$\\textbf{This model with SMOTE may  not be as accurate with other sets of data.}$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/miniconda3/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/miniconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/miniconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/miniconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/miniconda3/lib/python3.9/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from random import randrange, uniform\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Time'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V20       V21  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ...  0.251412 -0.018307   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.524980  0.247998   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  1.475829  0.213454   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.059616  0.214205   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.001396  0.232045   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.127434  0.265245   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        Amount  \n",
       "0       149.62  \n",
       "1         2.69  \n",
       "2       378.66  \n",
       "3       123.50  \n",
       "4        69.99  \n",
       "...        ...  \n",
       "284802    0.77  \n",
       "284803   24.79  \n",
       "284804   67.88  \n",
       "284805   10.00  \n",
       "284806  217.00  \n",
       "\n",
       "[284807 rows x 29 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Class'], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Class']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is arbitrary to choose the ratio of the the positive class to negative class. \n",
    "\n",
    "On the SMOTE API reference, it states that: \n",
    "\n",
    "class imblearn.over_sampling.SMOTE(*, $\\textbf{sampling_strategy='auto'}$ , random_state=None, k_neighbors=5, n_jobs=None)\n",
    "\n",
    "We notice that if we leave the field sampling_strategy parameters empty, the SMOTE function will automatically adjust the ratio between the positive and negative classes to 1:1. This is highly undesirable, as it will be overfitted to a degree that the kNN function will not be very useful with other data.\n",
    "\n",
    "Let's set the sampling strategy by multiplying the original ratio of 0.001727485630620034 by 1.5, since the original kNN classification without SMOTE was already at 93%. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy=ratio*1.5, random_state=100, k_neighbors=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       736\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that we have created more synthetic output samples. Let's use X_res and y_res on our kNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_SMOTE, X_test_SMOTE, y_train_SMOTE, y_test_SMOTE = train_test_split(X_res,y_res,random_state = 0, test_size = 0.2)\n",
    "\n",
    "#normalize data\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train_SMOTE = sc_X.fit_transform(X_train_SMOTE)\n",
    "X_test_SMOTE = sc_X.transform(X_test_SMOTE)\n",
    "\n",
    "# 11 neighbours for each point, p = 2 sets calculation of each point to the neighbours to use euclidean distance.\n",
    "classifier = KNeighborsClassifier(n_neighbors = 11, p =2, metric = 'euclidean')\n",
    "\n",
    "#pfloat, default=2 Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "classifier.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "classifier.predict(X_test_SMOTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_SMOTE = classifier.predict_proba(X_test_SMOTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_SMOTE, y_scores_SMOTE[:, 1])\n",
    "roc_auc_SMOTE = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_SMOTE)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'b--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN classifier with SMOTE ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the ROC curve is improved to 0.99, which is significantly higher than 0.93. \n",
    "\n",
    "However, this comes at a price of exchanging robustness for accuracy; when this model comes to a new dataset of credit card fraud, we may not see such a great performance. For example, this kNN model may be adept at detecting the current method that the fraudsters are using (maybe they use the stolen credit card on Amazon, then on Apple stores), but if they change up their tactics, this method may fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jinja2==3.0.3\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.3-cp39-cp39-macosx_10_9_universal2.whl (17 kB)\n",
      "Installing collected packages: MarkupSafe, jinja2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.22.1 which is incompatible.\n",
      "flask 3.0.0 requires Jinja2>=3.1.2, but you have jinja2 3.0.3 which is incompatible.\u001b[0m\n",
      "Successfully installed MarkupSafe-2.1.3 jinja2-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -I jinja2==3.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
